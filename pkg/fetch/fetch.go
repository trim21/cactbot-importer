package fetch

import (
	"bytes"
	"context"
	"fmt"
	"net/url"
	"strconv"
	"strings"

	"github.com/gofiber/fiber/v2"
	"github.com/pkg/errors"
	"github.com/sirupsen/logrus"
	"golang.org/x/sync/errgroup"
	"golang.org/x/sync/semaphore"

	"cactbot_importer/pkg/http"
	"cactbot_importer/pkg/repo"
	"cactbot_importer/pkg/wrap"
)

var ErrNotValidUrl = errors.New("不是有效的HTTP网址")

func Fetch(urls []string) (string, error) {
	w := bytes.NewBuffer(nil)
	ref := make(map[*url.URL]*url.URL)
	added := make(map[*url.URL]struct{})
	processedUrls := make([]*url.URL, 0, len(urls))

	w.WriteString("// generated by https://cactbot-importer.trim21.cn/\n")
	w.WriteString("// included files:\n//\n")

	add := func(url *url.URL, msg string) bool {
		if _, ok := added[url]; ok {
			w.WriteString(msg + url.String() + " [skipped]\n")
			return false
		} else {
			w.WriteString(msg + url.String() + "\n")
			added[url] = struct{}{}
			processedUrls = append(processedUrls, url)
			return true
		}
	}

	for _, u := range urls {
		uu, err := url.ParseRequestURI(strings.TrimSpace(u))
		if err != nil {
			return "", errors.Wrapf(err, strconv.Quote(u))
		}
		if uu.Scheme != "http" && uu.Scheme != "https" && uu.Host == "" {
			return "", errors.Wrapf(ErrNotValidUrl, strconv.Quote(u))
		}

		u = strings.TrimSpace(u)
		if strings.HasSuffix(uu.Path, ".json") {
			w.WriteString("// " + u + "\n")

			urls, err := repo.Fetch(u)
			if err != nil {
				if errors.Is(err, repo.ErrNestedRepo) {
					return "", wrap.Rewrite(err, fmt.Sprintf("不能嵌套repo %s", u))
				}
				return "", err
			}

			for _, ur := range urls {
				if add(ur, "//   ") {
					ref[ur] = uu
				}
			}
			w.WriteString("//\n")
		} else {
			add(uu, "// ")
		}
	}

	w.WriteString("\n")

	err := joinURLs(w, processedUrls, ref)
	if err != nil {
		return "", err
	}
	return w.String(), nil
}

var sem = semaphore.NewWeighted(4)

func joinURLs(w *bytes.Buffer, urls []*url.URL, ref map[*url.URL]*url.URL) error {
	res := make([]http.Response, len(urls))
	var g, ctx = errgroup.WithContext(context.Background())

	{
		uu := make([]string, len(urls))
		for i, u := range urls {
			uu[i] = u.String()
		}
		logrus.WithField("urls", uu).Infoln("joinUrls")
	}

	for i, u := range urls {
		u := u
		i := i
		err := sem.Acquire(context.Background(), 1)
		if err != nil {
			return err
		}
		g.Go(func() error {
			defer sem.Release(1)
			u.RawQuery = ""
			striped := &url.URL{
				Scheme: u.Scheme,
				Host:   u.Host,
				Path:   u.Path,
			}

			resp, err := http.GetWithCtx(ctx, striped)
			if err != nil {
				return fiber.NewError(fiber.StatusBadGateway, "无法获取链接 "+strconv.Quote(striped.String()))
			}
			if resp.StatusCode() >= 300 {
				if v, found := ref[u]; found {
					return fmt.Errorf("无法获取合集 %s\n\n文件 %s 消失", v, u.String())
				}
				return fmt.Errorf("无法获取文件 %s", u.String())
			}
			res[i] = resp
			return nil
		})
	}

	if err := g.Wait(); err != nil {
		return err
	}

	for _, resp := range res {
		t, err := process(resp)
		if err != nil {
			if errors.Is(err, ErrTransform) {
				return wrap.Rewrite(err, t)
			}
			return err
		}
		w.WriteString("// start " + resp.URL() + "\n")
		w.WriteString("console.log('cactbot importer: [INFO] executing script from " + resp.URL() + "');\n")
		w.WriteString(t)
		w.WriteString("// end " + resp.URL() + "\n\n")
	}

	return nil
}
